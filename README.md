# Introduction to data pipeline management with Airflow

The modern Data Warehouse increase in complexity it is necessary to have a dependable, scalable, intuitive, and simple scheduling and management program to monitor the flow of data and watch how transformations are completed.

Apache Airflow, help manage the complexities of their Enterprise Data Warehouse, is being adopted by tech companies everywhere for its ease of management, scalability, and elegant design. Airflow is rapidly becoming the go-to technology for companies scaling out large data warehouses.

The Introduction to the data pipeline management with Airflow training course is designed to familiarize participants with the use of Airflow schedule and maintain numerous ETL processes running on a large scale Enterprise Data Warehouse. The class cover with the hands-on exercises on,

- Introduction to Airflow framework and python
- Introduction to Airflow core concepts (DAGs, tasks, operators, sensors)
- Airflow UI
- Airflow scheduler
- Airflow operators & Sensors - deep dive
- Hooks, connections, and variablesâ€¨
- templating with Airflow
- SLA, monitoring & alerting

Participants should have a technology background, basic programming skills in Python and be open to sharing their thoughts and questions.

Participants need to bring their laptops. Further information about the technical environment will be communicated after registration.
